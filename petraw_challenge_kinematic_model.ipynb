{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JJ9-fITgaoCh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/pbs.2740561.pbsha.ib.sockeye/matplotlib-yfflptp4 because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim, as_tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "from torchvision.models.resnet import resnet18, resnet34, resnet50\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "num_gpu = torch.cuda.device_count()\n",
    "print('num GPUs: {}'.format(num_gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqUy0O_Rp84q",
    "outputId": "29c99f57-ead9-4bad-a266-1985f7d4a62c"
   },
   "outputs": [],
   "source": [
    "kin_data = pd.read_csv('dataset_path/inputs.csv', index_col = 0)\n",
    "output_data  = pd.read_csv('dataset_path/outputs.csv', index_col = 0)\n",
    "frame_data = np.load('dataset_path/video_frames.npy') \n",
    "seg_data = pd.read_csv('dataset_path/Segmentation.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYjPqIfnqqif",
    "outputId": "4664a83d-6096-45fc-f299-f4edd2d31103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Mapping Dictionary: \n",
      "\n",
      "Phase Dict: {'Idle': 0, 'Transfer Left to Right': 1, 'Transfer Right to Left': 2}\n",
      "Step Dict: {'Idle': 0, 'Block 1 L2R': 1, 'Block 2 L2R': 2, 'Block 3 L2R': 3, 'Block 4 L2R': 4, 'Block 5 L2R': 5, 'Block 6 L2R': 6, 'Block 1 R2L': 7, 'Block 2 R2L': 8, 'Block 3 R2L': 9, 'Block 4 R2L': 10, 'Block 5 R2L': 11, 'Block 6 R2L': 12}\n",
      "Verb Left Dict: {'Idle': 0, 'Catch': 1, 'Extract': 2, 'Hold': 3, 'Drop': 4, 'Touch': 5, 'Insert': 6}\n",
      "Verb Right Dict: {'Idle': 0, 'Catch': 1, 'Extract': 2, 'Hold': 3, 'Drop': 4, 'Touch': 5, 'Insert': 6}\n"
     ]
    }
   ],
   "source": [
    "Phase_dict = {output_data['Phase'].unique()[i]:i for i in range(len(output_data['Phase'].unique()))}\n",
    "Step_dict = {output_data['Step'].unique()[i]:i for i in range(len(output_data['Step'].unique()))}\n",
    "Verb_Left_dict = {output_data['Verb_Left'].unique()[i]:i for i in range(len(output_data['Verb_Left'].unique()))}\n",
    "Verb_Right_dict = Verb_Left_dict\n",
    "\n",
    "print('Output Mapping Dictionary: \\n')\n",
    "print('Phase Dict:', Phase_dict)\n",
    "print('Step Dict:', Step_dict)\n",
    "print('Verb Left Dict:', Verb_Left_dict)\n",
    "print('Verb Right Dict:', Verb_Right_dict)\n",
    "\n",
    "\n",
    "output_data['Phase'] = output_data['Phase'].map(Phase_dict)\n",
    "output_data['Step'] = output_data['Step'].map(Step_dict)\n",
    "output_data['Verb_Left'] = output_data['Verb_Left'].map(Verb_Left_dict)\n",
    "output_data['Verb_Right'] = output_data['Verb_Right'].map(Verb_Right_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "NAija1xRqS1T",
    "outputId": "239327dd-eca6-4593-b0a1-be2420fb9bb7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px_left</th>\n",
       "      <th>py_left</th>\n",
       "      <th>pz_left</th>\n",
       "      <th>q1_left</th>\n",
       "      <th>q2_left</th>\n",
       "      <th>q3_left</th>\n",
       "      <th>q4_left</th>\n",
       "      <th>ape_angle_left</th>\n",
       "      <th>lin_velo_x_left</th>\n",
       "      <th>lin_velo_y_left</th>\n",
       "      <th>...</th>\n",
       "      <th>q2_right</th>\n",
       "      <th>q3_right</th>\n",
       "      <th>q4_right</th>\n",
       "      <th>ape_angle_right</th>\n",
       "      <th>lin_velo_x_right</th>\n",
       "      <th>lin_velo_y_right</th>\n",
       "      <th>lin_velo_z_right</th>\n",
       "      <th>ang_velo_x_right</th>\n",
       "      <th>ang_velo_y_right</th>\n",
       "      <th>ang_velo_z_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.49995</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>2.682210e-07</td>\n",
       "      <td>-0.353608</td>\n",
       "      <td>-0.353590</td>\n",
       "      <td>-0.146429</td>\n",
       "      <td>0.853547</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353626</td>\n",
       "      <td>0.146404</td>\n",
       "      <td>0.85356</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>-0.000821</td>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.49995</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>3.576280e-07</td>\n",
       "      <td>-0.353608</td>\n",
       "      <td>-0.353591</td>\n",
       "      <td>-0.146429</td>\n",
       "      <td>0.853547</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353627</td>\n",
       "      <td>0.146404</td>\n",
       "      <td>0.85356</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>-0.000821</td>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.49995</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>1.788140e-07</td>\n",
       "      <td>-0.353608</td>\n",
       "      <td>-0.353591</td>\n",
       "      <td>-0.146429</td>\n",
       "      <td>0.853547</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353627</td>\n",
       "      <td>0.146404</td>\n",
       "      <td>0.85356</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>-0.000821</td>\n",
       "      <td>0.000338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.49995</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>1.788140e-07</td>\n",
       "      <td>-0.353608</td>\n",
       "      <td>-0.353591</td>\n",
       "      <td>-0.146429</td>\n",
       "      <td>0.853547</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353627</td>\n",
       "      <td>0.146404</td>\n",
       "      <td>0.85356</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.49995</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>5.960460e-08</td>\n",
       "      <td>-0.353608</td>\n",
       "      <td>-0.353591</td>\n",
       "      <td>-0.146429</td>\n",
       "      <td>0.853547</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353627</td>\n",
       "      <td>0.146404</td>\n",
       "      <td>0.85356</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   px_left  py_left       pz_left   q1_left   q2_left   q3_left   q4_left  \\\n",
       "0 -1.49995   1.0001  2.682210e-07 -0.353608 -0.353590 -0.146429  0.853547   \n",
       "1 -1.49995   1.0001  3.576280e-07 -0.353608 -0.353591 -0.146429  0.853547   \n",
       "2 -1.49995   1.0001  1.788140e-07 -0.353608 -0.353591 -0.146429  0.853547   \n",
       "3 -1.49995   1.0001  1.788140e-07 -0.353608 -0.353591 -0.146429  0.853547   \n",
       "4 -1.49995   1.0001  5.960460e-08 -0.353608 -0.353591 -0.146429  0.853547   \n",
       "\n",
       "   ape_angle_left  lin_velo_x_left  lin_velo_y_left  ...  q2_right  q3_right  \\\n",
       "0            15.0        -0.000004        -0.000004  ...  0.353626  0.146404   \n",
       "1            15.0        -0.000004        -0.000004  ...  0.353627  0.146404   \n",
       "2            15.0        -0.000003        -0.000004  ...  0.353627  0.146404   \n",
       "3            15.0        -0.000003        -0.000004  ...  0.353627  0.146404   \n",
       "4            15.0        -0.000003        -0.000004  ...  0.353627  0.146404   \n",
       "\n",
       "   q4_right  ape_angle_right  lin_velo_x_right  lin_velo_y_right  \\\n",
       "0   0.85356             15.0         -0.000002         -0.000004   \n",
       "1   0.85356             15.0         -0.000002         -0.000004   \n",
       "2   0.85356             15.0         -0.000002         -0.000004   \n",
       "3   0.85356             15.0         -0.000002         -0.000004   \n",
       "4   0.85356             15.0         -0.000002         -0.000004   \n",
       "\n",
       "   lin_velo_z_right  ang_velo_x_right  ang_velo_y_right  ang_velo_z_right  \n",
       "0         -0.000003          0.000650         -0.000821          0.000337  \n",
       "1         -0.000003          0.000650         -0.000821          0.000337  \n",
       "2         -0.000003          0.000649         -0.000821          0.000338  \n",
       "3         -0.000003          0.000648         -0.000823          0.000340  \n",
       "4         -0.000001          0.000681         -0.000816          0.000321  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Input Features #####\n",
    "kin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "9EcDDWPzqf8j",
    "outputId": "afc20d32-dfcd-49a3-d515-96d7fc83196c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>Step</th>\n",
       "      <th>Verb_Left</th>\n",
       "      <th>Verb_Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Phase  Step  Verb_Left  Verb_Right\n",
       "0      0     0          0           0\n",
       "1      0     0          0           0\n",
       "2      0     0          0           0\n",
       "3      0     0          0           0\n",
       "4      0     0          0           0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Output Features #####\n",
    "output_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No. of Video Frames:  378522\n"
     ]
    }
   ],
   "source": [
    "##### frames #####\n",
    "print('Total No. of Video Frames: ',len(frame_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>folder_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/arc/project/st-anaray02-1/skumar40/petraw_dat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/arc/project/st-anaray02-1/skumar40/petraw_dat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/arc/project/st-anaray02-1/skumar40/petraw_dat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/arc/project/st-anaray02-1/skumar40/petraw_dat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/arc/project/st-anaray02-1/skumar40/petraw_dat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  folder_name\n",
       "0  /arc/project/st-anaray02-1/skumar40/petraw_dat...            1\n",
       "1  /arc/project/st-anaray02-1/skumar40/petraw_dat...            1\n",
       "2  /arc/project/st-anaray02-1/skumar40/petraw_dat...            1\n",
       "3  /arc/project/st-anaray02-1/skumar40/petraw_dat...            1\n",
       "4  /arc/project/st-anaray02-1/skumar40/petraw_dat...            1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Segmentation map #####\n",
    "seg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5SZzWRSTz6tl"
   },
   "outputs": [],
   "source": [
    "class GeneralVideoDataset(Dataset):\n",
    "    \"\"\"Dataset Class for Loading Video\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        seg=None,\n",
    "        frame=None,\n",
    "        kin=None,\n",
    "        output=None,\n",
    "        time_depth=None,\n",
    "        train= False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            seg (data_frame/numpy array):  DF during test time /numpy array containing all\n",
    "                                            imagenet encoded frames (2048) during training\n",
    "            frame (data_frame/numpy array): DF during test time /numpy array containing all\n",
    "                                            imagenet encoded frames (2048) during training\n",
    "            kin (data_frame): pandas DF containing Kinematic data\n",
    "            output (data_frame): pandas DF containing Output data\n",
    "            train (bool): False if using for Test data/ True for Train data\n",
    "        \"\"\"\n",
    "        self.kin_df = kin\n",
    "        self.output_df = output\n",
    "        self.train = train\n",
    "        self.time_depth = time_depth\n",
    "        \n",
    "        ### For test dataset ###\n",
    "        if not self.train:\n",
    "            self.frame_df = frame\n",
    "            self.seg_df = seg\n",
    "            self.transform = T.Compose([T.Resize((224, 224)),\n",
    "                                        T.ToTensor()])\n",
    "            assert len(self.seg_df) == len(self.frame_df) == len(self.kin_df) == len(self.output_df)\n",
    "        ### For train dataset ###\n",
    "        else:\n",
    "            self.seg_np = seg\n",
    "            self.frame_np = frame\n",
    "            assert len(self.seg_np) == len(self.frame_np) == len(self.kin_df) == len(self.output_df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.kin_df)\n",
    "\n",
    "    def read_image(self, df, idx):\n",
    "        # Load the image file\n",
    "        image = Image.open(df.iloc[idx]['file_path'])\n",
    "        x = self.transform(image)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if not self.train:\n",
    "            video_frame = self.read_image(self.frame_df, idx)\n",
    "#             seg_map = self.read_image(self.seg_df, idx)\n",
    "        else:\n",
    "            video_frame = torch.from_numpy(self.frame_np[idx]).float()\n",
    "#             seg_map = torch.from_numpy(self.seg_np[idx]).float()\n",
    "\n",
    "        kinematic = torch.from_numpy(self.kin_df.iloc[idx].to_numpy()).float().unsqueeze_(0)\n",
    "        output = torch.from_numpy(self.output_df.iloc[idx].to_numpy())\n",
    "\n",
    "        sample = {\n",
    "            \"video\": video_frame,\n",
    "#             \"segmenation\": seg_map,\n",
    "            \"Kinematic\": kinematic,\n",
    "            \"output\": output,\n",
    "        }\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NormalizeLayer(torch.nn.Module):\n",
    "#     \"\"\"Standardize the channels of a batch of images by subtracting the dataset mean\n",
    "#       and dividing by the dataset standard deviation.\n",
    "\n",
    "#       In order to certify radii in original coordinates rather than standardized coordinates, we\n",
    "#       add the Gaussian noise _before_ standardizing, which is why we have standardization be the first\n",
    "#       layer of the classifier rather than as a part of preprocessing as is typical.\n",
    "#       \"\"\"\n",
    "\n",
    "#     def __init__(self, means, sds):\n",
    "#         \"\"\"\n",
    "#         :param means: the channel means\n",
    "#         :param sds: the channel standard deviations\n",
    "#         \"\"\"\n",
    "#         super(NormalizeLayer, self).__init__()\n",
    "#         self.means = torch.tensor(means).cuda()\n",
    "#         self.sds = torch.tensor(sds).cuda()\n",
    "\n",
    "#     def forward(self, input: torch.tensor):\n",
    "#         (batch_size, num_channels, height, width) = input.shape\n",
    "#         means = self.means.repeat((batch_size, height, width, 1)).permute(0, 3, 1, 2)\n",
    "#         sds = self.sds.repeat((batch_size, height, width, 1)).permute(0, 3, 1, 2)\n",
    "#         return (input - means)/sds\n",
    "\n",
    "# class Identity(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Identity, self).__init__()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         return x\n",
    "    \n",
    "    \n",
    "# norm_layer = NormalizeLayer(means=[0.485, 0.456, 0.406],\n",
    "#                             sds=[0.229, 0.224, 0.225])\n",
    "\n",
    "# resnet50_imagenet = resnet50(pretrained=False).cuda()\n",
    "# resnet50_img_weight_path = 'pretrained_model/checkpoint.pth.tar'\n",
    "# checkpoint = torch.load(resnet50_img_weight_path)\n",
    "# new_state_dict = OrderedDict()\n",
    "\n",
    "# for k, v in checkpoint['state_dict'].items():\n",
    "#     if k[:1]!=str(0):\n",
    "#         name = k[9:] # remove `module.`\n",
    "#         new_state_dict[name] = v\n",
    "\n",
    "# resnet50_imagenet.load_state_dict(new_state_dict)\n",
    "# resnet50_imagenet.fc = Identity()\n",
    "# resnet50_imagenet = torch.nn.Sequential(norm_layer, resnet50_imagenet)\n",
    "\n",
    "# for param50 in resnet50_imagenet.parameters():\n",
    "#     param50.requires_grad = False\n",
    "    \n",
    "# print('resnet 50 loaded and layers freezed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "L6ORIovZgc7O"
   },
   "outputs": [],
   "source": [
    "class petraw_model(nn.Module):\n",
    "    def __init__(self, imagenet_extractor=None, input_size=28, hidden_layer_size=64, hidden_size=32, output_size=None, train_p=True):\n",
    "        super(petraw_model, self).__init__()\n",
    "        self.train_p = train_p\n",
    "        if not self.train_p:\n",
    "            self.imagenet_extractor = imagenet_extractor\n",
    "        \n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        ### Video Layers\n",
    "        self.fc_ex1 = nn.Linear(2048, 512)\n",
    "        self.fc_ex2 = nn.Linear(512, 256)\n",
    "        self.fc_ex3 = nn.Linear(256, 64)\n",
    "        \n",
    "\n",
    "        ## Video Frame-> Imagenet_extractor-> 2048 -> Fc_ex1 -> Fc_ex2 -> Fc_ex3 -> Ourt 1\n",
    "        \n",
    "        ### output-layers\n",
    "        self.fc_F = nn.Linear(hidden_size + 64, output_size)\n",
    "\n",
    "#         self.fc3 = nn.Linear(hidden_size + 64, 13)\n",
    "\n",
    "#         self.fc4 = nn.Linear(hidden_size + 64, 7)\n",
    "\n",
    "#         self.fc5 = nn.Linear(hidden_size + 64, 7)\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, input_image):\n",
    "        \n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq)\n",
    "        lin_out = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        lin_out = self.relu(lin_out)\n",
    "        \n",
    "        if not self.train_p:\n",
    "            x = self.imagenet_extractor(input_image)\n",
    "        else:\n",
    "            x = input_image\n",
    "        x = self.fc_ex1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc_ex2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc_ex3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        y_f = self.fc_F(torch.cat((lin_out, x), dim=1))\n",
    "\n",
    "        return y_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "h6_-_co6HiDW"
   },
   "outputs": [],
   "source": [
    "kin_train, kin_test, frame_train, frame_test, seg_train, seg_test, output_train, output_test = train_test_split(kin_data, frame_data, seg_data, output_data, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DWeY-E6tenN6"
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "train_data = GeneralVideoDataset(kin=kin_train, \n",
    "                                 frame=frame_train, \n",
    "                                 seg=seg_train, \n",
    "                                 output=output_train,\n",
    "                                 train=True)\n",
    "train_loader = DataLoader(train_data, bs, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "### test acts as validation ###\n",
    "test_data = GeneralVideoDataset(kin=kin_test, \n",
    "                                frame=frame_test, \n",
    "                                seg=seg_test, \n",
    "                                output=output_test,\n",
    "                                train=True)\n",
    "test_loader = DataLoader(test_data, bs, shuffle=False, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ULgcxsTzmDrN"
   },
   "outputs": [],
   "source": [
    "def calculate_loss(out, y, criterion):\n",
    "    l1 = torch.tensor(0.0).cuda()\n",
    "    for (a,b) in zip(out, y.T):\n",
    "        l1 += criterion(a, b)\n",
    "    return l1\n",
    "\n",
    "def calculate_correct(out, y):\n",
    "    correct = []\n",
    "    for (a,b) in zip(out, y.T):\n",
    "        pred = nn.Softmax(dim=1)(a).max(dim=1)[1]\n",
    "        correct.append(torch.eq(pred, b).sum().item())\n",
    "    return correct\n",
    "\n",
    "\n",
    "\n",
    "def train(epochs, train_loader, test_loader, model_list, criterion, print_acc_epoch, name):\n",
    "    for i in range(epoch):\n",
    "        \n",
    "        for m in range(len(model_list)):\n",
    "            model_list[m][0] = model_list[m][0].train()\n",
    "            \n",
    "        epoch_loss_train = [0, 0, 0, 0]\n",
    "        epoch_loss_test = [0, 0, 0, 0]\n",
    "\n",
    "        total_train = 0\n",
    "        correct_train = [0, 0, 0, 0]\n",
    "        total_test = 0\n",
    "        correct_test = [0, 0, 0, 0]\n",
    "\n",
    "        for batch_idx, data_dict in enumerate(train_loader):\n",
    "            sys.stdout.write(\"\\rBatch: {}\".format(batch_idx+1))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            X1, X2, y = data_dict['Kinematic'].cuda(), data_dict['video'].cuda(), data_dict['output'].cuda()\n",
    "            \n",
    "            output_list = []\n",
    "            for m in range(len(model_list)):\n",
    "                model, optimizer = model_list[m]\n",
    "                out = model(X1, X2)\n",
    "                loss = criterion(out, y.T[m])\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss_train[m] += loss.item()\n",
    "                output_list.append(out.detach())\n",
    "                model_list[m] = [model, optimizer]\n",
    "\n",
    "            if (i+1)%print_acc_epoch==0:\n",
    "                total_train += len(y)\n",
    "                new_corr = calculate_correct(output_list, y)\n",
    "                correct_train = [correct_train[i] + new_corr[i] for i in range(len(correct_train))]\n",
    "\n",
    "        epoch_loss_train = [round(epoch_loss_train[k]/(batch_idx+1), 2) for k in range(len(epoch_loss_train))]\n",
    "    \n",
    "        model_save_dir = 'trained_models/'\n",
    "        if not os.path.isdir(model_save_dir):\n",
    "            os.makedirs(model_save_dir)\n",
    "            \n",
    "        model_save_path = model_save_dir + name + '.pth.tar'\n",
    "        torch.save(model_list, model_save_path)\n",
    "\n",
    "        if (i+1)%print_acc_epoch!=0:\n",
    "            sys.stdout.write(' || Epoch: {}, Loss: {}\\n'.format(i+1, epoch_loss_train))\n",
    "\n",
    "        if (i+1)%print_acc_epoch==0:\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                for batch_idx, data_dict in enumerate(test_loader):\n",
    "\n",
    "                    output_list = []\n",
    "                    for m in range(len(model_list)):\n",
    "                        model, optimizer = model_list[m]\n",
    "                        model.eval()\n",
    "                        out = model(X1, X2)\n",
    "                        loss = criterion(out, y.T[m])\n",
    "\n",
    "                        epoch_loss_test[m] += loss.item()\n",
    "                        output_list.append(out.detach())\n",
    "\n",
    "                    total_test += len(y)\n",
    "                    new_corr = calculate_correct(output_list, y)\n",
    "                    correct_test = [correct_test[i] + new_corr[i] for i in range(len(correct_test))]\n",
    "\n",
    "            epoch_loss_test = [round(epoch_loss_test[k]/(batch_idx+1), 2) for k in range(len(epoch_loss_test))]\n",
    "            test_acc = [round((correct_test[i]/total_test), 2) * 100 for i in range(len(correct_test))]\n",
    "            train_acc = [round((correct_train[i]/total_train), 2) * 100 for i in range(len(correct_train))]\n",
    "\n",
    "            sys.stdout.write('\\nEpoch: {}\\n'.format(i+1))\n",
    "            sys.stdout.write('Train tasks ACC: {}\\n'.format(train_acc))\n",
    "            sys.stdout.write('Test tasks ACC: {}\\n'.format(test_acc))\n",
    "            sys.stdout.write('Train Loss: {}\\n'.format(epoch_loss_train))\n",
    "            sys.stdout.write('Test Loss: {}\\n'.format(epoch_loss_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "we_wXDCkyrqf",
    "outputId": "abe2cedb-7cbf-4fc3-aea1-db3f09fa8635"
   },
   "outputs": [],
   "source": [
    "models_opt_list = []\n",
    "output_size_list = [3,13,7,7]\n",
    "models_lr_list = [0.01, 0.001, 0.01, 0.01]\n",
    "\n",
    "for i in range(4):\n",
    "    kbm = petraw_model(output_size = output_size_list[i]).cuda()\n",
    "    kbm = nn.DataParallel(kbm)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    optimizer = optim.Adam(params = kbm.parameters(),\n",
    "                           lr = models_lr_list[i])\n",
    "    \n",
    "    models_opt_list.append([kbm, optimizer])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 4141 || Epoch: 1, Loss: [2.33, 2.32, 0.63, 0.88]\n",
      "Batch: 4141 || Epoch: 2, Loss: [0.5, 2.01, 0.42, 0.38]\n",
      "Batch: 4141 || Epoch: 3, Loss: [0.42, 1.76, 0.39, 0.35]\n",
      "Batch: 4141 || Epoch: 4, Loss: [0.38, 1.5, 0.36, 0.31]\n",
      "Batch: 4141\n",
      "Epoch: 5\n",
      "Train tasks ACC: [87.0, 50.0, 89.0, 91.0]\n",
      "Test tasks ACC: [60.0, 100.0, 100.0, 100.0]\n",
      "Train Loss: [0.36, 1.31, 0.34, 0.29]\n",
      "Test Loss: [0.65, 0.57, 0.0, 0.15]\n",
      "Batch: 4141 || Epoch: 6, Loss: [0.35, 1.19, 0.34, 0.28]\n",
      "Batch: 4141 || Epoch: 7, Loss: [0.33, 1.11, 0.31, 0.27]\n",
      "Batch: 4141 || Epoch: 8, Loss: [0.31, 1.03, 0.3, 0.26]\n",
      "Batch: 4141 || Epoch: 9, Loss: [0.3, 0.98, 0.29, 0.25]\n",
      "Batch: 4141\n",
      "Epoch: 10\n",
      "Train tasks ACC: [90.0, 65.0, 91.0, 92.0]\n",
      "Test tasks ACC: [100.0, 100.0, 100.0, 100.0]\n",
      "Train Loss: [0.29, 0.94, 0.28, 0.25]\n",
      "Test Loss: [0.18, 0.16, 0.0, 0.2]\n",
      "Batch: 4141 || Epoch: 11, Loss: [0.28, 0.89, 0.28, 0.24]\n",
      "Batch: 4141 || Epoch: 12, Loss: [0.27, 0.86, 0.28, 0.24]\n",
      "Batch: 4141 || Epoch: 13, Loss: [0.27, 0.83, 0.26, 0.23]\n",
      "Batch: 4141 || Epoch: 14, Loss: [0.28, 0.81, 0.26, 0.23]\n",
      "Batch: 4141\n",
      "Epoch: 15\n",
      "Train tasks ACC: [91.0, 71.0, 92.0, 93.0]\n",
      "Test tasks ACC: [100.0, 100.0, 100.0, 100.0]\n",
      "Train Loss: [0.27, 0.78, 0.25, 0.23]\n",
      "Test Loss: [0.17, 0.14, 0.0, 0.23]\n",
      "Batch: 4141 || Epoch: 16, Loss: [0.27, 0.76, 0.25, 0.23]\n",
      "Batch: 4141 || Epoch: 17, Loss: [0.26, 0.75, 0.25, 0.22]\n",
      "Batch: 4141 || Epoch: 18, Loss: [0.24, 0.74, 0.25, 0.22]\n",
      "Batch: 4141 || Epoch: 19, Loss: [0.25, 0.71, 0.24, 0.22]\n",
      "Batch: 4141\n",
      "Epoch: 20\n",
      "Train tasks ACC: [92.0, 74.0, 92.0, 93.0]\n",
      "Test tasks ACC: [80.0, 100.0, 100.0, 100.0]\n",
      "Train Loss: [0.23, 0.7, 0.24, 0.22]\n",
      "Test Loss: [0.33, 0.15, 0.0, 0.14]\n",
      "Batch: 4141 || Epoch: 21, Loss: [0.23, 0.68, 0.23, 0.21]\n",
      "Batch: 313"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-752518:\n",
      "Traceback (most recent call last):\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/multiprocessing/connection.py\", line 737, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b77b04df09e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_opt_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multi_model_training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-8c7fd5008595>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, train_loader, test_loader, model_list, criterion, print_acc_epoch, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/arc/project/st-anaray02-1/skumar40/jupyter/me_jpy/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "\n",
    "train(epoch, train_loader, test_loader, models_opt_list, criterion, 5, 'multi_model_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "petraw_challenge_kinematic_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "me_jpy",
   "language": "python",
   "name": "me_jpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
